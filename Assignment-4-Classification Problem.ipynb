{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad130bdf-f9d9-428a-89ac-bb3481cdc87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduction : In this notebook, we will apply learning techniques on the breast cancer dataset from sklearn library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74a24b8a-df19-4d5d-8543-f66d475c6cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and Preprocessing\n",
    "\n",
    "# Importing required libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7969bbfe-8437-404c-b95f-7b743a8bc46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd28b70-b560-443a-9a22-3a30a610e7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(X.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59db3ea5-b516-429b-99ab-892e4bc631ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d152916d-6f52-41c7-bd18-c944e0475495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f90ba07b-30d9-4019-8248-d4880c5cd460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Algorithm Implementation\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50d2c261-d38c-4316-94a9-cf95bf12ef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Accuracy:\", acc_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1259539a-0dfa-4402-9a9b-c8f8acd9a8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Accuracy:\", acc_dt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e30125a1-1e8c-4144-b0d2-219e77460d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", acc_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9822d53b-45d0-41f6-9a3b-94d8ef08662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Accuracy:\", acc_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc47f082-c3e7-4531-8940-92c442e72970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# k-Nearest Neighbors\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"k-NN Accuracy:\", acc_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05c2bcaf-9bb0-4cdb-ae37-00b108766e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.9737\n",
      "Decision Tree: 0.9474\n",
      "Random Forest: 0.9649\n",
      "SVM: 0.9737\n",
      "k-NN: 0.9474\n"
     ]
    }
   ],
   "source": [
    "# Model Comparison\n",
    "\n",
    "results = {\n",
    "    'Logistic Regression': acc_lr,\n",
    "    'Decision Tree': acc_dt,\n",
    "    'Random Forest': acc_rf,\n",
    "    'SVM': acc_svm,\n",
    "    'k-NN': acc_knn\n",
    "}\n",
    "\n",
    "# Print results\n",
    "for model, acc in results.items():\n",
    "    print(f\"{model}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab7235-f2a7-4c99-9805-c19ba600b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY / Explanation\n",
    "\n",
    "**Missing Values**: Checked using `isnull()`. The dataset has no missing values.ie, value = 0.\n",
    "**Feature Scaling**: Used `StandardScaler` to scale features. Scaling is important for algorithms like SVM and k-NN to perform well.\n",
    "**Train-Test Split**: Used an 80-20 split to evaluate model performance on unseen data.\n",
    "\n",
    "**Logistic Regression** is a linear model for binary classification. It is effective when classes are linearly separable. Since breast cancer is a binary problem (malignant/benign), it's a good starting point.\n",
    "**Random Forest** is an ensemble method combining multiple decision trees to improve accuracy and prevent overfitting.\n",
    "**SVM** finds the optimal hyperplane that separates classes. It performs well with high-dimensional data and is robust to overfitting.\n",
    "**k-NN** classifies data points based on the majority label of the k-nearest neighbors. It's simple but sensitive to the choice of k and feature scaling.\n",
    "\n",
    "    **Best Performing**: Usually Random Forest or SVM.\n",
    "    **Least Performing**: Often Decision Tree or k-NN due to overfitting or sensitivity to data scaling.\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
